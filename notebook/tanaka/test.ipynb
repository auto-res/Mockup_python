{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "#from src.creator.tanaka.main import Creator\n",
    "from src.coder.main import Coder\n",
    "from src.evaluator.main import Evaluator\n",
    "\n",
    "llm_name = \"gpt-4-turbo-preview\"\n",
    "#llm_name = \"gpt-3.5-turbo-0125\"\n",
    "#llm_name = \"gemini-pro\"\n",
    "#llm_name = \"claude-3-opus-20240229\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初めに入力されるモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_code = \"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train(trainloader, params, device):\n",
    "    net = Net()\n",
    "    net.to(device)  # Move the model to the specified device\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=params['lr'])\n",
    "\n",
    "    for epoch in range(1):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)  # Move inputs and labels to the specified device\n",
    "\n",
    "            optimizer.zero_grad()  # zero the parameter gradients\n",
    "\n",
    "            outputs = net(inputs)  # forward + backward + optimize\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                running_loss = 0.0\n",
    "\n",
    "    return net\n",
    "\n",
    "def test(net, testloader, device):\n",
    "    all_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)  # Move images to the specified device\n",
    "            outputs = net(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            probabilities_np = probabilities.cpu().numpy().tolist()  # Move the probabilities back to CPU for numpy conversion\n",
    "            all_outputs.extend(probabilities_np)\n",
    "\n",
    "    all_outputs_np = np.array(all_outputs)\n",
    "    return all_outputs_np\n",
    "\n",
    "def model(trainloader, testloader, params):\n",
    "    device = torch.device(\"cuda\")# if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA (GPU support) is available in this environment.\")\n",
    "    net = train(trainloader, params, device)\n",
    "    y_pred = test(net, testloader, device)\n",
    "    return y_pred\n",
    "\"\"\"\n",
    "\n",
    "with open(\"/Users/tanakatouma/vscode/Mockup_python/data/base_model.py\", \"w\") as file:\n",
    "    file.write(base_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creatorの出力として欲しい形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_method = \"\"\"\n",
    "<ELEMENTAL_METHOD name=\"Momentum Calculation and Application\">\n",
    "This method involves computing the moving average of the gradients (also known as the first moment) and using this to update the model parameters. It's a technique used to accelerate gradients vectors in the right directions, thus leading to faster converging. It is widely used in optimization algorithms, including as a component of the Adam optimizer.\n",
    "\n",
    "<PYTHON>\n",
    "def momentum_update(lr, beta1, params, objective, weight_decay, epsilon):\n",
    "    m = 0  # first moment\n",
    "    theta = params\n",
    "    while True:\n",
    "        g = np.gradient(objective(theta), theta)  # gradient of objective function\n",
    "        if weight_decay != 0:\n",
    "            g += weight_decay * theta\n",
    "        m = beta1 * m + (1 - beta1) * g\n",
    "        theta -= lr * m\n",
    "        yield theta\n",
    "</PYTHON>\n",
    "</ELEMENTAL_METHOD>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(\"/Users/tanakatouma/vscode/Mockup_python/data/new_method.txt\", \"w\") as file:\n",
    "    file.write(new_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = Coder(llm_name = llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file_path = \"/Users/tanakatouma/vscode/Mockup_python/data/base_model.py\"\n",
    "new_method_path = \"/Users/tanakatouma/vscode/Mockup_python/data/new_method.txt\"\n",
    "save_file_path=\"/Users/tanakatouma/vscode/Mockup_python/data/exec_code.py\"\n",
    "\n",
    "exec_code_path = coder.exec(base_file_path, new_method_path, save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tanakatouma/vscode/Mockup_python/data/exec_code.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_code_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': {'type': 'log_float', 'args': [1e-8, 0.1]},\n",
    "    'iterations': {'type': 'log_float', 'args': [100, 1000]},\n",
    "    \"lambda\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "eval = Evaluator(\n",
    "    llm_name=llm_name,\n",
    "    dataset_name='cifar10',\n",
    "    params=params,\n",
    "    valuation_index='accuracy',\n",
    "    datasave_path='../../data',\n",
    "    n_trials=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = eval.exec(exec_code_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実際にループを回す場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_name = \"gpt-4-turbo-preview\"\n",
    "#llm_name = \"gpt-3.5-turbo-0125\"\n",
    "#llm_name = \"gemini-pro\"\n",
    "#llm_name = \"claude-3-opus-20240229\"\n",
    "\n",
    "\n",
    "#creator = Creator(llm_name=llm_name)\n",
    "\n",
    "coder = Coder(\n",
    "    llm_name = llm_name\n",
    "    )\n",
    "\n",
    "eval = Evaluator(\n",
    "    llm_name=llm_name,\n",
    "    dataset_name='cifar10',\n",
    "    params=params,\n",
    "    valuation_index='accuracy',\n",
    "    datasave_path='../../data',\n",
    "    n_trials=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一番初めにベースモデルの評価から行うためevaluatorから実行\n",
    "# 10回の改善を行う\n",
    "\n",
    "for i in range(10):\n",
    "    file_name = f'exec_code_{i}.py'\n",
    "    result = eval.exec(exec_code_path)\n",
    "    base_code_path = exec_code_path\n",
    "    if i == 9:\n",
    "        break\n",
    "    #new_method_path = creator.exec(base_code, result)\n",
    "    exec_code_path = coder.exec(base_code_path, new_method_path, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
